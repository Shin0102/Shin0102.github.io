[{"content":"고려해야 될점  Service Discovery : Container가 Scailing 되어도 해당서비스를 찾을 수 있어야 함 API Gateway : 외부에서 내부의 서비스들에 접근에 대한 제어(인증, 로깅, 모니터링, Response) Load balance : Container나 Instance 성능을 위해 외부요청을 적절히 분배 Cirecuit Breaker : 하나의 서비스 장애가 전체 서비스의 장애가 되지 않아야함 IPC : 서비스 사이의 통신  Sync : HTTP, gRPC Async : RabbitMQ, AWS SQS, Kafka, Kinesis 등등   DDD (Domain Drive Design -\u0026gt; Event storming, Bounded context) : MSA를 어떻게 구성할지에 대한 방법론  MSA Pattern  SAGA : MSA에서의 트랜잭션 처리  Choreography-Based Saga Orchestrations-Based Saga   Event Source : 발생하는 모든 event를 event table의 저장 CQRS : CUD와 Read를 분리(AWS DynamoDB와 같은 DB와 sync), Event Source 패턴과 결합  ","description":"","id":0,"section":"posts","tags":["MSA"],"title":"MSA 설계시 고려해야될 점과 Pattern","uri":"https://Shin0102.github.io/posts/devops-msa-considerations/"},{"content":"들어가며  작년부터 회사의 거대한 레거시 시스템을 Python 기반의 API 서버로 조금씩 포팅하고 있다. 한번에 모두 포팅하기란 불가능하기에 MSA를 기반으로 여러 기능들로 나누어(메시지, 결제, 고객용 API 등등\u0026hellip;) 포팅을 진행하였다. 하지만 처음에 배포환경이나 Framework 대한 결정없이 각각 진행하다보니, AWS EC2, Lambda, ECS등 다양한 환경에서 API 서버들이 돌아갔다. 그러다 보니 해당 모듈의 담당자가 없으면 서비스를 배포하기가 힘든 환경이 되었고, 배포를 위해서 노트북마다 환경에 맞는 세팅이 필요하게 되었다. 이러한 상황을 극복하기 위해 배포환경을 통일하는게 필요하였고, 그래서 아래와 같이 EKS 기반의 배포 자동화 파이프라인을 구축하였다.\nKubernetes 배포 자동화 배포 자동화를 위한 EKS pipeline:  \n참고. MSA를 위한 Kubernetes 세팅과 CI/CD Pipeline 구성\n구성하는데 위 블로그의 도움을 많이 받았으며, 크게 다른점은 Jenkins 대신에 CDK로 AWS CodePipeline을 생성하여 사용하였다. 간단히 Flow를 설명하면 아래와 같다.\nflow 1. Code commit\n2. AWS CodePipeline에서 Code commit 이벤트를 받아 Docker Build 하고 ECR에 해당 이미지를 Push\n3. AWS CodePipeline에서 GitOps repository에 있는 helm values file을 업데이트 (이미지 태그나 secret value 등등)\n4. AWS CodePipeline \u0026lsquo;success\u0026rsquo; 또는 \u0026lsquo;fail\u0026rsquo;을 슬랙으로 알림\n5. argocd 에서 Girpops repository의 변경내역이 발생하면, 변경된 내용을 기반으로 자동(or 수동)으로 Kubernetes내의 Resource를 업데이트 한다.\n실제 운영중인 gui:  \n실제로 위와 같이 배포 파이프라인을 구축하고 난 뒤에는 배포에 대한 부담이 많이 줄어들었다. 배포를 위한 다른 세팅이나 Kubernetes Cluster 접근할 필요없이 argocd gui를 통해 배포 \u0026amp; 롤백을 매우 편하게 할 수 있게 되었기 때문이다. 하지만 프로젝트를 새로 생성 할때마다, AWS CodePipeline을 추가를 해줘야하는 수고스러움?이 발생한다. 물론 CDK를 이용하여 이것도 자동화를 하였지만, 매번 AWS CodePipeline을 생성해야 된다는 것이 그렇게 반가운 상황은 아니었다. 그렇게 고민하던중 github action을 알게 되었고, 파이프라인 구축을 좀 더 간소화 할 수 있을것 같은 기대감을 가지고 세팅을 시작해보았다.(github action을 써보고 싶기도 하였다..)\ngithub action  github action이란 github에서 제공하는 CI/CD 툴이다. 사용법은 간단하다. gitub project에 Actions 탭에 들어가면 새로운 workflow를 만들 수 있다. yml 파일로 만들어지며, 생성된 파일은 default로 .github/workflows/{name}.yml 위치하게 된다. 자세한 설명은 잘 정리해주신 블로거가 많으니 참고하면 될 것 같다. 일단 해야될 work을 정해보면 아래와 같다.\n docker build AWS ECR push GitOps repository의 Kubernetes deployment.yaml image tag를 update  \nGitOps repostroy의 Kubernetes deploymnet.yaml의 image tag에 빌드된 이미지의 태그가 업데이트 되면, GitOps repository와 연동해놓은 argocd 에서 자동(or 수동)으로 Cluster에 해당하는 Pod를 업데이트 하여 sync를 맞춘다. 일단 위 작업들을 정의한 github action은 아래와 같다.\n project name : 테스트라 가정. gitops repo 아래 경로에 k8s yaml(service, deployment)이 정의되어있다고 가정.  gitops repo/dev/테스트/resources.yaml gitops repo/prod/테스트/resources.yaml   (github action을 수행하기전에 아래 값들을 github secrets에 세팅필요)\n  Github Secrets   AWS_ACCESS_KEY_ID_VAL AWS_SECRET_ACCESS_KEY_VAL ECR_REPOSITORY -\u0026gt; AWS ECR Repository 이름 GIT_ACCESS_TOKEN -\u0026gt; gitops git repsitory를 checkout 하기위한 Token     예제 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  on:push:branches:- master- featurename:Docker Image build \u0026amp; k8s resources.yaml updatejobs:deploy:name:Deployruns-on:ubuntu-lateststeps:- name:Checkoutuses:actions/checkout@v2- name:Set Dev env variablesif:endsWith(github.ref, \u0026#39;/feature\u0026#39;)run:|echo \u0026#34;Feature branch\u0026#34; echo \u0026#34;ENVIRONMENT=dev\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;DESTINATION=dev/테스트\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;BRANCH=feature\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV- name:Set Prod env variablesif:endsWith(github.ref, \u0026#39;/master\u0026#39;)run:|echo \u0026#34;Master branch\u0026#34; echo \u0026#34;ENVIRONMENT=prod\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;DESTINATION=prod/테스트\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;BRANCH=master\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV- name:Set commit msg env:GITHUB_SHA:${{ github.sha }}run:|echo \u0026#34;COMMIT_MSG=Update from https://github.com/your/테스트/$GITHUB_SHA\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo $COMMIT_MSG## Push app image to ECR#- name:Configure AWS credentialsuses:aws-actions/configure-aws-credentials@v1with:aws-access-key-id:${{ secrets.AWS_ACCESS_KEY_ID_VAL }}aws-secret-access-key:${{ secrets.AWS_SECRET_ACCESS_KEY_VAL }}aws-region:ap-northeast-2- name:Login to Amazon ECRid:login-ecruses:aws-actions/amazon-ecr-login@v1- name:Build, tag, and push image to Amazon ECRid:build-imageenv:ECR_REGISTRY:${{ steps.login-ecr.outputs.registry }}ECR_REPOSITORY:${{ secrets.ECR_REPOSITORY }}IMAGE_TAG:${{ github.sha }}run:|docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$ENVIRONMENT-$IMAGE_TAG {Dockerfile 경로} docker push $ECR_REGISTRY/$ECR_REPOSITORY:$ENVIRONMENT-$IMAGE_TAG echo \u0026#34;::set-output name=image::$ECR_REGISTRY/$ECR_REPOSITORY:$ENVIRONMENT-$IMAGE_TAG\u0026#34; ## Update Image tag to delployment.yaml#- name:Git configrun:|git config --global user.email \u0026#34;actions@github.com\u0026#34; git config --global user.name \u0026#34;GitHub Actions\u0026#34; - name:Check out k8s repouses:actions/checkout@masterwith:repository:your/gitops-repositorytoken:${{ secrets.GIT_ACCESS_TOKEN }}- name:chmod repo destinationrun:|chmod +x $DESTINATION ls - name:git push image tag to k8 repo env:GITHUB_REPO:${{ github.repository.name }}GITHUB_SHA:${{ github.sha }}run:|sed -i -e \u0026#39;s@${{ steps.login-ecr.outputs.registry }}/${{ secrets.ECR_REPOSITORY }}:.*@${{ steps.build-image.outputs.image }}@g\u0026#39; $DESTINATION/resources.yaml git add . git commit -m \u0026#34;$COMMIT_MSG\u0026#34; git push -f --set-upstream origin main   구조를 보면 트리거 / build 환경 / 실제 수행할 step들이 정의되어 있다. feature, master branch 에 push될때 dev와 production 서버를 업데이트 하기위한 github action이다. 라인별 설명은 아래와 같다.\nline 19~33 : GitOps repository에 해당 프로젝트의 kubernetes 리소스들이 있는 path를 지정해준다.(dev, prod)\nline 39 : GitOps에 commit할 msg 지정 -\u0026gt; 현재 commit의 url link를 commit msg로 하기위해 repository url을 세팅해준다.\nline 55~64 : docker build하고 지정한 ECR에 push\nline 74~78 : GitOps repository checkout\nline 80~83 : 실행권한 추가\nline 85~93 : k8s deployment가 정의된 yaml 파일의 tag를 업데이트\nAWS CodePipeline과 비교  일단 기존의 사용하던 codepipe line과 비교해보면 사용법이 굉장히 쉬웠다. AWS Codepipeline도 iac tool 을 이용해서 쉽게 세팅할 수 있지만, 초기 세팅이 쉽지는 않았다. 그리고 github action이 좋았던 것이 브랜치별로 pipeline을 구성할 필요가 없다는 것이 굉장히 편리했다. step에서 조건문을 이용하면 branch 별로 action을 제어할 수 있다. 마지막으로 빌드 시간에서 생각보다 많은 차이가 났다. 기존 CodePipeline을 사용했을때는 5~6분정도 소요 되었는데 github action은 절반도 안되는 시간이(2분 정도) 소요되었다.\n참고. GitHub Actions vs. AWS CodePipeline\n마치며  AWS CodePipeline에서 github action으로 cd pipeline을 변경하면서 구성이 굉장히 가벼워진 느낌이 들었다. 프로젝트 내에서 branch별로 pipeline을 만들 필요도 없고, 간단히 프로젝트 repository에 workflow가 정의된 yml파일만 추가해주면 되기 때문이다. 결과적으로는 github을 repository로 사용하고 있고, AWS Resource에 의존성이 크지 않으면 github action을 사용하지 않을 이유는 없을 것 같다.\n","description":"","id":1,"section":"posts","tags":["github action","Kubernetes","argocd"],"title":"github action으로 Kubernetes 배포 자동화","uri":"https://Shin0102.github.io/posts/devops-github-action/"},{"content":" MSA(microservice architectur)를 위해 CDK(typescript)를 통해 EKS를 구성한 적이 있는데, 이때는 동작에만 집중하다 보니, 자동으로 생성되는 리소스나 Role들에 대해 크게 신경 쓰지 않았다. 그러다 이번에 번잡하게 관리되는 AWS Resource들에 대해 정리할 기회가 생겨, 새로 EKS 환경을 구성할 기회가 생겼다. 그중에 이번에는 Role에 대해 정리해보려 한다.\n CDK를 통해 eks를 생성하게 되면 role에 대해 특별히 명시하지 않아도, 자동으로 IAM Role들이 몇 개 만들어진다. Cluster에 대한 Role, 그리고 같이 생성되는 Lambda에 대한 Role도 여러 개 있다.(Lambda 관련된 것들은 다음에 정리해봐야겠다) 먼저 Cluster 관련 Role을 정리해 보면 아래와 같다.\nKubernetes v1.18, CDK 1.78.0/ 세팅에 따라 이름이나, Role 개수가 다를 수 있음\n1. {cluster-name}-ClusterCreationRole\n2. {cluster-name}-admin-role\n3. {cluster-name}-eks-role\n4. {cluster-name}-ClusterNodegroupNodesNodeGroupRole 1. {cluster-name}-ClusterCreationRole  먼저 {cluster-name}-ClusterCreationRole을 살펴보면, ClusterCreationRoleDefaultPolicy라는 인라인 Policy(이것도 자동으로 생성됨)가 연결되어있다. 정책 내용에는 EKS Cluster를 생성에 사용할 Subnet과 VPC에 대한 정보에 대한 접근 허용, Cluster 생성/삭제/버전업데이트 등 클러스터 생성에 관한 권한들이 나열되어 있다. 내용이나 이름으로 보아 cdk에서 cluster 생성 및 관리할때 사용하는 Role 이다.\n2. {cluster-name}-admin-role  {cluster-name}-admin-role은 확인해보면 아무런 Policy도 연결되어 있지 않다. 그래서 좀 찾아보니 먼저 EKS인증 방식을 알아야 한다.\nAWS 인증방식: https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/managing-auth.html  \nkubectl 을 통해 Cluster에 접근하게 되면 해당 유저가 적절한 I AM User인지 확인한 후, 인증되면 k8s(Kubernetes)의 RBAC을 이용해 접근제어를 하게 된다. {cluster-name}-admin-role은 Cluster를 초기 생성하는 User에게 system:masters라는 그룹을 부여하게 된다. 이 그룹은 k8s Default ClusterRole인 cluster-admin(super user)이라는 ClusterRole과 바인딩되어 있다. 그래서 Cluster 초기 생성자는 Cluster관한 거의 모든 권한을 가지고 있다.\n참고. k8s default cluster role and role bidings 3. {cluster-name}-eks-role  {cluster-name}-eks-role은 AmazonEKSClusterPolicy라는 기존 Policy가 연결되어 있는데, 설명을 보면 아래와 같다.\nThis policy provides Kubernetes the permissions it requires to manage resources on your behalf. Kubernetes requires Ec2:CreateTags permissions to place identifying information on EC2 resources including but not limited to Instances, Security Groups, and Elastic Network Interfaces.\nk8s 에서 AWS 리소스들을 관리하기 위해 필요한 권한들이라는 설명이다. Policy를 확인해보면 EC2, Load Balancer, AutoscalingGroup 등 서비스 운영에 주요한 리소스들에 대한 권한들이 포함되어 있다. AWS Console에 들어가보면 생성한 Cluster에 해당 Role이 연결되어 있는것을 확인할 수 있다.\n4. {cluster-name}-ClusterNodegroupNodesNodeGroupRole  마지막으로 {{cluster-name}-ClusterNodegroupNodesNodeGroupRole을 확인해보면, 총 3가지의 AWS Policy가 연결되어있다.\n AmazonEKSWorkerNodePolicy : EKS Worker node를 EKS Cluster에 연결하기 위한 Policy AmazonEC2ContainerRegistryReadOnly : ECR(컨테이너 저장소) Readonly Policy AmazonEKS_CNI_Policy : EKS에서 Conatiner 들의 Network Interface들을 관리하기 위해 EKS는 AWS CNI라는 plugin을 사용하는데, 해당 플러그인에게 제공하는 Policy   확인해 보니 Container Image를 읽어와 Worker Node안에 Pod들을 배포할때 필요한 정책들이 들어가 있다. 실제로 Worker Node들은 EC2 Instance에 해당하고, Pod들은 이 Worker Node들 안에 적절히? 배포된다.\n 이제 Role들에 대해 알아봤으니, 실제 구성한 환경에서 확인해보자. 아래 명령어로 eks 생성시 만들어진 aws-auth configmap을 확인할 수 있다. aws-auth configmap을 수정을 통해 클러스터에 접근하는 유저나 Role을 관리할 수 있으며, 아래 명령어를 통해 수정하거나 yaml을 통해 적용가능하다.\n1  kubectl edit -n kube-system configmap/aws-auth   aws auth configmap  \n처음 eks를 생성하면 aws configmap이 위와 같이 정의되어 있다. (실제로 String 형태로 되어있었지만 가독성을 위해 위 형식으로 수정하였다.). 위에서 설명한 Workder Node관련 Role과 Cluster 초기 생성자와 관련된 Role이 보인다.\nmapUsers에는 원래 아무것도 없었지만, EKS 생성후에 AWS Console EKS에서 Nodegroup에 대한 정보가 제대로 나오지않고 \u0026lsquo;Your current user or role does not have access to Kubernetes objects on this EKS cluster\u0026rsquo; 에러가 나와서 로그인한 I Am user에 master 권한을 추가해주니 정상적으로 Nodegroup 정보가 출력되었다. 다른유저들이 EKS Cluster에 접근하게 추가하고싶으면 mapUsers부분에 추가해주면 된다.\n 이글은 아래 내용을 많이 참고하였고, EKS 환경을 구성하게 된다면 꼭 한번 보기를 추천한다. Custom Role과 Group을 만드는 내용도 있어 다음에 필요하면 세팅해볼 예정이다.\n쿠알못이 Amazon EKS로 안정적인 서비스 운영하기\n","description":"","id":2,"section":"posts","tags":["aws eks","cdk","role","iam"],"title":"AWS EKS Role에 대한 고찰","uri":"https://Shin0102.github.io/posts/devops-aws-eks-role/"},{"content":"hugo zzo 테마에서 사용 가능한 shortcodes  기본적으로 Markdown 문법도 제공하지만, 아래 shortcode들도 사용가능해서 블로그 쓰는데 유용할 것 같다. 이외에도 flowchartjs등 차트라이브러리도 사용가능하다.\nthis is a text this is a text this is a text this is a text   Expand me  Some Markdown Contents   Image4: Image description   success  color Some contents  Some markdown contents Windows MacOS Ubuntu  Windows section 1  console.log(\u0026#39;Hello World!\u0026#39;);     MacOS section Hello world!  Ubuntu section Great!    'use strict'; var containerId = JSON.parse(\"\\\"12abf4928132c6bd\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  emoji-cheat-sheet   I ❤️ 🐟\nzzo theme document\n","description":"","id":3,"section":"posts","tags":["zzo theme"],"title":"zzo theme shortcodes","uri":"https://Shin0102.github.io/posts/etc-zzo-theme-shotcodes/"},{"content":"   Experience Python(Django, FastAPI, Flask) Backend Developer\nAWS, EKS, Serverless Devops\nMigration legacy services to microservices\nInterst Full stack Developer(Learning React)\nDeep dive devops\nGolang\n","description":"Alli about page","id":4,"section":"","tags":null,"title":"About","uri":"https://Shin0102.github.io/about/"}]