[{"content":"어쩌다?  3년 넘게 다니던 회사를 그만두게 되고, 타이밍 좋게? 지인소개로 새로 런칭하는 서비스(재능기부 플랫폼)의 백엔드 개발에 참여하게 되었다. 레거시 없이 내가 원하는 백엔드 인프라를 구성할수 있다는 점과 초기멤버로 서비스 런칭한다는 점이 끌려 입사하게 되었다. 입사당시 팀원은 대표, CTO, 나 세명이었고 추가적으로 백엔드 팀원 두명의 TO와 프론트엔드 외주가 예정되어 있었고, 서비스 기획이 어느정도 마무리 되는 시점이여서 첫 한달은 비즈니스를 이해하고 인프라 설계 및 API 설계하는데 주력하였다. 그렇게 어느정도 개발 윤곽이 나오고 \u0026lsquo;이제 달리기만 하면 된다\u0026rsquo; 생각했다. 하지만 살면서 계획대로 되는일이 얼마나 되겠는가\u0026hellip;😂 뭐 많은일들이 있었지만 결론적으로는 마크업과 앱 배포만 외주로 지원받고 나머지는 혼자 개발하기로 스스로 결정하였다. 기대반 두려움반 이렇게 1인개발 여정이 시작되었다. 🚴🏼🚴🏼🚴🏼\n어쩌지?  백엔드 구성은 어느정도 CTO님과 얘기하며 어느정도 윤곽이 나왔다. MSA로 구성하였으며 terraform을 이용하여 AWS EKS로 구축하기로 했다. 추후 스케일링 뿐만아니라 자동화 파이프라인을 구축하여 개발에 집중하기 좋을거라 생각했다. DDD(Domain Driven Design) 방법론을 이용하여 개발해야할 모듈이 4개로 정했으며, 원래는 JAVA Spring으로 진행하고 싶었지만 짧은기간(약 6개월)에 프론트엔드 개발도 동시에 진행해야 했기에 익숙한 Python Django로 진행하고 다른 작은모듈은 Python fastapi나 Node express를 사용하였다. 백엔드 파트는 그래도 경험했던 분야라 일정도 어느정도 예상할수 있었고 진행에 큰 무리가 없을거라 생각했다.\n 문제는 프론트엔드\u0026hellip;😫 간단하게는 그냥 fullstack Framework를 사용하면 된다.(Django면 Template이나 Jinja) 하지만 예전에 경험해봤을때, 규모가 커지면 개발이 너무 복잡해져 힘들었다. 그래서 이번에는 React를 사용하여 한번 개발해보기로 결정하였다(개인적인 욕심+😋). React 경험이 없어, 처음에는 러닝커브가 어느정도 있을거라 예상했지만 어느정도 익숙해지면 오히려 속도가 더 나올것이라 예상했다. 이렇게 1인 개발 여정이 시작되었다.\nTech Stack 인프라 : AWS, IaC(terraform), CI/CD(github action, argocd), Docker, k8s\n백엔드 : Python(django), Node + Typescript(express)\n프론트엔드 : React + Typescript 실제 구성 구성한 인프라:  \n좀 더 자세한 구성은 위 그림과 같이 하였다. 프론트엔드 부분 구성과 배포는 AWS amplify로 구축하였다. AWS cognito(인증)와 같이 기타 AWS 서비스 연결과 자동배포, 호스팅등 간단하게 풀스택 세팅할 수 있기 때문이다. (백엔드의 경우는 amplify를 사용하지 않았다.) 인증의 경우 위에 적었듯이 AWS cognito를 사용하였으며 Frontend에서 각 API에 접근하기 위해 AWS ALB path routing을 세팅하였다.\n어떻게 됨?  3월부터 팀에 참가해서 4월부터 본격적으로 개발을 시작하였다. 결론적으로는 9월 중순에 (총 6개월 정도 소요)해서 요구한 기능들을 모두 개발하여 내부테스트까지 진행하였다. 개발한 내용은 프론트엔드 + 4개의 백엔드 모듈(비즈니스 로직 관련 API, SNS 인증 관련 API, 기타 알림이나 주소관련 API, 채팅 API)이다. 하지만 회사 사정으로 앱 출시까지는 하지 못하고 프로젝트를 종료하게 되었다. (너무 아쉽다😰😰)\n어땠어?  좋은 점은 일단 혼자서 인프라 구축부터 프론트엔드, 백엔드 개발까지 혼자 경험해본 것이 매우 귀중한 경험이었다고 생각한다. 실제 인증은 어떤 Flow로 진행되는지, 프론트엔드와 백엔드 사이에서 데이터를 주고받을때 어떻게 해야 효율적인지? 여러가지를 고민을 해볼 수 있는 시간이었다.(백엔드만 개발했을때는 고민해보지 못한 그런\u0026hellip;?) 그리고 생각보다는 할만하네? 라고 생각이 들었다. 초기 인프라 및 CI/CD 자동화를 세팅하였기 때문에 그 뒤로는 개발에만 집중할 수 있었기 때문이었다. 물론 프론트엔드 React를 개발하면서 많은 난관이 있었다. 처음 해본 언어였기 때문일수도 있고, html 에 대한 이해도 부족했고 마크업도 외주로 진행하다보니 제대로 된 지원을 받기 어려웠다. 그리고 실제 사용자가 사용하는 화면을 개발하는것이라 그런지 꼼꼼하게 체크할(예외처리나 편의성 부분)부분이 많이 있어 생각했던 것 보다 작업량이 많았다. (존경합니다. 프론트엔드 개발자님들)\n 힘들었던 점은 아무래도 코드 퀄리티에 많은 신경을 쓰기 힘들다는 점이다. 혼자서 많은 양을 정해진 일정 안에 개발해야 하기 때문에 점점 마음에 들지 않는 코딩을 하게 되었다. 그리고 내부에서 조언을 구하거나 도움을 받을 팀원이 없다는 점이었다. 정신없이 코딩하게 되면 어느 순간에 삽질의 순간에 빠지게 되는데, 이때 해결되지 않으면 멘붕의 순간에 빠진다. 지나고 보면 별것도 아닌데 그 순간에 누군가 같이 고민해줬다면 훨씬 빠른시간 안에 해결할 수 있었을 것이라 생각한다.(외로움\u0026hellip;😰😰)\n 약 7개월간의 1인 개발여정을 짧은글로 정리하면서 스스로에 대한 뿌듯함이 들기도 하고, 많이 힘들었던 기억도 지나가는 것 같다. 이번 경험이 좋은 밑거름이 되길 바라며 이만\u0026hellip;\nps. 스타트업이면 AWS activate 신청하세요.(기본 1,000$에 설문조사도 하면 추가로 300$ 지원받더라구요😋)\n","description":"","id":0,"section":"posts","tags":["1인 개발, AWS activate, 풀스택"],"title":"1인 개발로 서비스 런칭하며...","uri":"https://Shin0102.github.io/posts/indie-developer/"},{"content":"고려해야 될점  Service Discovery : Container가 Scailing 되어도 해당서비스를 찾을 수 있어야 함 API Gateway : 외부에서 내부의 서비스들에 접근에 대한 제어(인증, 로깅, 모니터링, Response) Load balance : Container나 Instance 성능을 위해 외부요청을 적절히 분배 Cirecuit Breaker : 하나의 서비스 장애가 전체 서비스의 장애가 되지 않아야함 IPC : 서비스 사이의 통신  Sync : HTTP, gRPC Async : RabbitMQ, AWS SQS, Kafka, Kinesis 등등   DDD (Domain Drive Design -\u0026gt; Event storming, Bounded context) : MSA를 어떻게 구성할지에 대한 방법론  MSA Pattern  SAGA : MSA에서의 트랜잭션 처리  Choreography-Based Saga Orchestrations-Based Saga   Event Source : 발생하는 모든 event를 event table의 저장 CQRS : CUD와 Read를 분리(AWS DynamoDB와 같은 DB와 sync), Event Source 패턴과 결합  ","description":"","id":1,"section":"posts","tags":["MSA"],"title":"MSA 설계시 고려해야될 점과 Pattern","uri":"https://Shin0102.github.io/posts/devops-msa-considerations/"},{"content":"들어가며  작년부터 회사의 거대한 레거시 시스템을 Python 기반의 API 서버로 조금씩 포팅하고 있다. 한번에 모두 포팅하기란 불가능하기에 MSA를 기반으로 여러 기능들로 나누어(메시지, 결제, 고객용 API 등등\u0026hellip;) 포팅을 진행하였다. 하지만 처음에 배포환경이나 Framework 대한 결정없이 각각 진행하다보니, AWS EC2, Lambda, ECS등 다양한 환경에서 API 서버들이 돌아갔다. 그러다 보니 해당 모듈의 담당자가 없으면 서비스를 배포하기가 힘든 환경이 되었고, 배포를 위해서 노트북마다 환경에 맞는 세팅이 필요하게 되었다. 이러한 상황을 극복하기 위해 배포환경을 통일하는게 필요하였고, 그래서 아래와 같이 EKS 기반의 배포 자동화 파이프라인을 구축하였다.\nKubernetes 배포 자동화 배포 자동화를 위한 EKS pipeline:  \n참고. MSA를 위한 Kubernetes 세팅과 CI/CD Pipeline 구성\n구성하는데 위 블로그의 도움을 많이 받았으며, 크게 다른점은 Jenkins 대신에 CDK로 AWS CodePipeline을 생성하여 사용하였다. 간단히 Flow를 설명하면 아래와 같다.\nflow 1. Code commit\n2. AWS CodePipeline에서 Code commit 이벤트를 받아 Docker Build 하고 ECR에 해당 이미지를 Push\n3. AWS CodePipeline에서 GitOps repository에 있는 helm values file을 업데이트 (이미지 태그나 secret value 등등)\n4. AWS CodePipeline \u0026lsquo;success\u0026rsquo; 또는 \u0026lsquo;fail\u0026rsquo;을 슬랙으로 알림\n5. argocd 에서 Girpops repository의 변경내역이 발생하면, 변경된 내용을 기반으로 자동(or 수동)으로 Kubernetes내의 Resource를 업데이트 한다.\n실제 운영중인 gui:  \n실제로 위와 같이 배포 파이프라인을 구축하고 난 뒤에는 배포에 대한 부담이 많이 줄어들었다. 배포를 위한 다른 세팅이나 Kubernetes Cluster 접근할 필요없이 argocd gui를 통해 배포 \u0026amp; 롤백을 매우 편하게 할 수 있게 되었기 때문이다. 하지만 프로젝트를 새로 생성 할때마다, AWS CodePipeline을 추가를 해줘야하는 수고스러움?이 발생한다. 물론 CDK를 이용하여 이것도 자동화를 하였지만, 매번 AWS CodePipeline을 생성해야 된다는 것이 그렇게 반가운 상황은 아니었다. 그렇게 고민하던중 github action을 알게 되었고, 파이프라인 구축을 좀 더 간소화 할 수 있을것 같은 기대감을 가지고 세팅을 시작해보았다.(github action을 써보고 싶기도 하였다..)\ngithub action  github action이란 github에서 제공하는 CI/CD 툴이다. 사용법은 간단하다. gitub project에 Actions 탭에 들어가면 새로운 workflow를 만들 수 있다. yml 파일로 만들어지며, 생성된 파일은 default로 .github/workflows/{name}.yml 위치하게 된다. 자세한 설명은 잘 정리해주신 블로거가 많으니 참고하면 될 것 같다. 일단 해야될 work을 정해보면 아래와 같다.\n docker build AWS ECR push GitOps repository의 Kubernetes deployment.yaml image tag를 update  \nGitOps repostroy의 Kubernetes deploymnet.yaml의 image tag에 빌드된 이미지의 태그가 업데이트 되면, GitOps repository와 연동해놓은 argocd 에서 자동(or 수동)으로 Cluster에 해당하는 Pod를 업데이트 하여 sync를 맞춘다. 일단 위 작업들을 정의한 github action은 아래와 같다.\n project name : 테스트라 가정. gitops repo 아래 경로에 k8s yaml(service, deployment)이 정의되어있다고 가정.  gitops repo/dev/테스트/resources.yaml gitops repo/prod/테스트/resources.yaml   (github action을 수행하기전에 아래 값들을 github secrets에 세팅필요)\n  Github Secrets   AWS_ACCESS_KEY_ID_VAL AWS_SECRET_ACCESS_KEY_VAL ECR_REPOSITORY -\u0026gt; AWS ECR Repository 이름 GIT_ACCESS_TOKEN -\u0026gt; gitops git repsitory를 checkout 하기위한 Token     예제 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  on:push:branches:- master- featurename:Docker Image build \u0026amp; k8s resources.yaml updatejobs:deploy:name:Deployruns-on:ubuntu-lateststeps:- name:Checkoutuses:actions/checkout@v2- name:Set Dev env variablesif:endsWith(github.ref, \u0026#39;/feature\u0026#39;)run:|echo \u0026#34;Feature branch\u0026#34; echo \u0026#34;ENVIRONMENT=dev\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;DESTINATION=dev/테스트\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;BRANCH=feature\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV- name:Set Prod env variablesif:endsWith(github.ref, \u0026#39;/master\u0026#39;)run:|echo \u0026#34;Master branch\u0026#34; echo \u0026#34;ENVIRONMENT=prod\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;DESTINATION=prod/테스트\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo \u0026#34;BRANCH=master\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV- name:Set commit msg env:GITHUB_SHA:${{ github.sha }}run:|echo \u0026#34;COMMIT_MSG=Update from https://github.com/your/테스트/$GITHUB_SHA\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV echo $COMMIT_MSG## Push app image to ECR#- name:Configure AWS credentialsuses:aws-actions/configure-aws-credentials@v1with:aws-access-key-id:${{ secrets.AWS_ACCESS_KEY_ID_VAL }}aws-secret-access-key:${{ secrets.AWS_SECRET_ACCESS_KEY_VAL }}aws-region:ap-northeast-2- name:Login to Amazon ECRid:login-ecruses:aws-actions/amazon-ecr-login@v1- name:Build, tag, and push image to Amazon ECRid:build-imageenv:ECR_REGISTRY:${{ steps.login-ecr.outputs.registry }}ECR_REPOSITORY:${{ secrets.ECR_REPOSITORY }}IMAGE_TAG:${{ github.sha }}run:|docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$ENVIRONMENT-$IMAGE_TAG {Dockerfile 경로} docker push $ECR_REGISTRY/$ECR_REPOSITORY:$ENVIRONMENT-$IMAGE_TAG echo \u0026#34;::set-output name=image::$ECR_REGISTRY/$ECR_REPOSITORY:$ENVIRONMENT-$IMAGE_TAG\u0026#34; ## Update Image tag to delployment.yaml#- name:Git configrun:|git config --global user.email \u0026#34;actions@github.com\u0026#34; git config --global user.name \u0026#34;GitHub Actions\u0026#34; - name:Check out k8s repouses:actions/checkout@masterwith:repository:your/gitops-repositorytoken:${{ secrets.GIT_ACCESS_TOKEN }}- name:chmod repo destinationrun:|chmod +x $DESTINATION ls - name:git push image tag to k8 repo env:GITHUB_REPO:${{ github.repository.name }}GITHUB_SHA:${{ github.sha }}run:|sed -i -e \u0026#39;s@${{ steps.login-ecr.outputs.registry }}/${{ secrets.ECR_REPOSITORY }}:.*@${{ steps.build-image.outputs.image }}@g\u0026#39; $DESTINATION/resources.yaml git add . git commit -m \u0026#34;$COMMIT_MSG\u0026#34; git push -f --set-upstream origin main   구조를 보면 트리거 / build 환경 / 실제 수행할 step들이 정의되어 있다. feature, master branch 에 push될때 dev와 production 서버를 업데이트 하기위한 github action이다. 라인별 설명은 아래와 같다.\nline 19~33 : GitOps repository에 해당 프로젝트의 kubernetes 리소스들이 있는 path를 지정해준다.(dev, prod)\nline 39 : GitOps에 commit할 msg 지정 -\u0026gt; 현재 commit의 url link를 commit msg로 하기위해 repository url을 세팅해준다.\nline 55~64 : docker build하고 지정한 ECR에 push\nline 74~78 : GitOps repository checkout\nline 80~83 : 실행권한 추가\nline 85~93 : k8s deployment가 정의된 yaml 파일의 tag를 업데이트\nAWS CodePipeline과 비교  일단 기존의 사용하던 codepipe line과 비교해보면 사용법이 굉장히 쉬웠다. AWS Codepipeline도 iac tool 을 이용해서 쉽게 세팅할 수 있지만, 초기 세팅이 쉽지는 않았다. 그리고 github action이 좋았던 것이 브랜치별로 pipeline을 구성할 필요가 없다는 것이 굉장히 편리했다. step에서 조건문을 이용하면 branch 별로 action을 제어할 수 있다. 마지막으로 빌드 시간에서 생각보다 많은 차이가 났다. 기존 CodePipeline을 사용했을때는 5~6분정도 소요 되었는데 github action은 절반도 안되는 시간이(2분 정도) 소요되었다.\n참고. GitHub Actions vs. AWS CodePipeline\n마치며  AWS CodePipeline에서 github action으로 cd pipeline을 변경하면서 구성이 굉장히 가벼워진 느낌이 들었다. 프로젝트 내에서 branch별로 pipeline을 만들 필요도 없고, 간단히 프로젝트 repository에 workflow가 정의된 yml파일만 추가해주면 되기 때문이다. 결과적으로는 github을 repository로 사용하고 있고, AWS Resource에 의존성이 크지 않으면 github action을 사용하지 않을 이유는 없을 것 같다.\n","description":"","id":2,"section":"posts","tags":["github action","Kubernetes","argocd"],"title":"github action으로 Kubernetes 배포 자동화","uri":"https://Shin0102.github.io/posts/devops-github-action/"},{"content":" MSA(microservice architectur)를 위해 CDK(typescript)를 통해 EKS를 구성한 적이 있는데, 이때는 동작에만 집중하다 보니, 자동으로 생성되는 리소스나 Role들에 대해 크게 신경 쓰지 않았다. 그러다 이번에 번잡하게 관리되는 AWS Resource들에 대해 정리할 기회가 생겨, 새로 EKS 환경을 구성할 기회가 생겼다. 그중에 이번에는 Role에 대해 정리해보려 한다.\n CDK를 통해 eks를 생성하게 되면 role에 대해 특별히 명시하지 않아도, 자동으로 IAM Role들이 몇 개 만들어진다. Cluster에 대한 Role, 그리고 같이 생성되는 Lambda에 대한 Role도 여러 개 있다.(Lambda 관련된 것들은 다음에 정리해봐야겠다) 먼저 Cluster 관련 Role을 정리해 보면 아래와 같다.\nKubernetes v1.18, CDK 1.78.0/ 세팅에 따라 이름이나, Role 개수가 다를 수 있음\n1. {cluster-name}-ClusterCreationRole\n2. {cluster-name}-admin-role\n3. {cluster-name}-eks-role\n4. {cluster-name}-ClusterNodegroupNodesNodeGroupRole 1. {cluster-name}-ClusterCreationRole  먼저 {cluster-name}-ClusterCreationRole을 살펴보면, ClusterCreationRoleDefaultPolicy라는 인라인 Policy(이것도 자동으로 생성됨)가 연결되어있다. 정책 내용에는 EKS Cluster를 생성에 사용할 Subnet과 VPC에 대한 정보에 대한 접근 허용, Cluster 생성/삭제/버전업데이트 등 클러스터 생성에 관한 권한들이 나열되어 있다. 내용이나 이름으로 보아 cdk에서 cluster 생성 및 관리할때 사용하는 Role 이다.\n2. {cluster-name}-admin-role  {cluster-name}-admin-role은 확인해보면 아무런 Policy도 연결되어 있지 않다. 그래서 좀 찾아보니 먼저 EKS인증 방식을 알아야 한다.\nAWS 인증방식: https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/managing-auth.html  \nkubectl 을 통해 Cluster에 접근하게 되면 해당 유저가 적절한 I AM User인지 확인한 후, 인증되면 k8s(Kubernetes)의 RBAC을 이용해 접근제어를 하게 된다. {cluster-name}-admin-role은 Cluster를 초기 생성하는 User에게 system:masters라는 그룹을 부여하게 된다. 이 그룹은 k8s Default ClusterRole인 cluster-admin(super user)이라는 ClusterRole과 바인딩되어 있다. 그래서 Cluster 초기 생성자는 Cluster관한 거의 모든 권한을 가지고 있다.\n참고. k8s default cluster role and role bidings 3. {cluster-name}-eks-role  {cluster-name}-eks-role은 AmazonEKSClusterPolicy라는 기존 Policy가 연결되어 있는데, 설명을 보면 아래와 같다.\nThis policy provides Kubernetes the permissions it requires to manage resources on your behalf. Kubernetes requires Ec2:CreateTags permissions to place identifying information on EC2 resources including but not limited to Instances, Security Groups, and Elastic Network Interfaces.\nk8s 에서 AWS 리소스들을 관리하기 위해 필요한 권한들이라는 설명이다. Policy를 확인해보면 EC2, Load Balancer, AutoscalingGroup 등 서비스 운영에 주요한 리소스들에 대한 권한들이 포함되어 있다. AWS Console에 들어가보면 생성한 Cluster에 해당 Role이 연결되어 있는것을 확인할 수 있다.\n4. {cluster-name}-ClusterNodegroupNodesNodeGroupRole  마지막으로 {{cluster-name}-ClusterNodegroupNodesNodeGroupRole을 확인해보면, 총 3가지의 AWS Policy가 연결되어있다.\n AmazonEKSWorkerNodePolicy : EKS Worker node를 EKS Cluster에 연결하기 위한 Policy AmazonEC2ContainerRegistryReadOnly : ECR(컨테이너 저장소) Readonly Policy AmazonEKS_CNI_Policy : EKS에서 Conatiner 들의 Network Interface들을 관리하기 위해 EKS는 AWS CNI라는 plugin을 사용하는데, 해당 플러그인에게 제공하는 Policy   확인해 보니 Container Image를 읽어와 Worker Node안에 Pod들을 배포할때 필요한 정책들이 들어가 있다. 실제로 Worker Node들은 EC2 Instance에 해당하고, Pod들은 이 Worker Node들 안에 적절히? 배포된다.\n 이제 Role들에 대해 알아봤으니, 실제 구성한 환경에서 확인해보자. 아래 명령어로 eks 생성시 만들어진 aws-auth configmap을 확인할 수 있다. aws-auth configmap을 수정을 통해 클러스터에 접근하는 유저나 Role을 관리할 수 있으며, 아래 명령어를 통해 수정하거나 yaml을 통해 적용가능하다.\n1  kubectl edit -n kube-system configmap/aws-auth   aws auth configmap  \n처음 eks를 생성하면 aws configmap이 위와 같이 정의되어 있다. (실제로 String 형태로 되어있었지만 가독성을 위해 위 형식으로 수정하였다.). 위에서 설명한 Workder Node관련 Role과 Cluster 초기 생성자와 관련된 Role이 보인다.\nmapUsers에는 원래 아무것도 없었지만, EKS 생성후에 AWS Console EKS에서 Nodegroup에 대한 정보가 제대로 나오지않고 \u0026lsquo;Your current user or role does not have access to Kubernetes objects on this EKS cluster\u0026rsquo; 에러가 나와서 로그인한 I Am user에 master 권한을 추가해주니 정상적으로 Nodegroup 정보가 출력되었다. 다른유저들이 EKS Cluster에 접근하게 추가하고싶으면 mapUsers부분에 추가해주면 된다.\n 이글은 아래 내용을 많이 참고하였고, EKS 환경을 구성하게 된다면 꼭 한번 보기를 추천한다. Custom Role과 Group을 만드는 내용도 있어 다음에 필요하면 세팅해볼 예정이다.\n쿠알못이 Amazon EKS로 안정적인 서비스 운영하기\n","description":"","id":3,"section":"posts","tags":["aws eks","cdk","role","iam"],"title":"AWS EKS Role에 대한 고찰","uri":"https://Shin0102.github.io/posts/devops-aws-eks-role/"},{"content":"hugo zzo 테마에서 사용 가능한 shortcodes  기본적으로 Markdown 문법도 제공하지만, 아래 shortcode들도 사용가능해서 블로그 쓰는데 유용할 것 같다. 이외에도 flowchartjs등 차트라이브러리도 사용가능하다.\nthis is a text this is a text this is a text this is a text   Expand me  Some Markdown Contents   Image4: Image description   success  color Some contents  Some markdown contents Windows MacOS Ubuntu  Windows section 1  console.log(\u0026#39;Hello World!\u0026#39;);     MacOS section Hello world!  Ubuntu section Great!    'use strict'; var containerId = JSON.parse(\"\\\"12abf4928132c6bd\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  emoji-cheat-sheet   I ❤️ 🐟\nzzo theme document\n","description":"","id":4,"section":"posts","tags":["zzo theme"],"title":"zzo theme shortcodes","uri":"https://Shin0102.github.io/posts/etc-zzo-theme-shotcodes/"},{"content":"   Experience Python(Django, FastAPI, Flask) Backend Developer\nAWS, EKS, Serverless Devops\nMigration legacy services to microservices\nInterst Full stack Developer(Learning React)\nDeep dive devops\nGolang\n","description":"Alli about page","id":5,"section":"","tags":null,"title":"About","uri":"https://Shin0102.github.io/about/"}]